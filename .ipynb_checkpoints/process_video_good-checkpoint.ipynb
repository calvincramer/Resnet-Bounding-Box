{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all successfully!\n"
     ]
    }
   ],
   "source": [
    "# import IPython;IPython.embed()\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "# Import things from actual YOLO folder\n",
    "sys.path.insert(0, '/root/PyTorch-YOLOv3')\n",
    "\n",
    "from models import *\n",
    "from utils.utils import *\n",
    "from utils.datasets import *\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import NullLocator\n",
    "\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "\n",
    "# Need?\n",
    "%matplotlib inline \n",
    "\n",
    "print(\"Imported all successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters to always use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "config_path = \"../PyTorch-YOLOv3/config/yolov3.cfg\"\n",
    "weights_path = \"../PyTorch-YOLOv3/weights/yolov3.weights\"\n",
    "class_path = \"../PyTorch-YOLOv3/data/coco.names\"\n",
    "conf_thres = 0.8\n",
    "nms_thres = 0.4\n",
    "batch_size = 1\n",
    "n_cpu = 8\n",
    "img_size = 416\n",
    "use_cuda = True\n",
    "cuda = torch.cuda.is_available() and use_cuda # Whether the gpu is available\n",
    "model = Darknet(config_path, img_size=img_size) # Set up model\n",
    "model.load_weights(weights_path)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "model.eval() # Set in evaluation mode\n",
    "classes = load_classes(class_path) # Extracts class labels from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bounding-box colors\n",
    "cmap = plt.get_cmap('tab20b')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer_draw_frame(frame):    \n",
    "    # Convert the frame into a tensor\n",
    "    frame_tensor = torch.from_numpy(frame)\n",
    "    frame_tensor = frame_tensor.unsqueeze(0) # Add the batch dimension\n",
    "    frame_tensor = frame_tensor.permute(0, 3, 1, 2) # Swap axes to [b,c,w,h] form\n",
    "    frame_tensor = frame_tensor.float() # Convert byte tensor to float tensor\n",
    "        \n",
    "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        detections = model(frame_tensor)\n",
    "        detections = non_max_suppression(detections, 80, conf_thres, nms_thres)\n",
    "        \n",
    "    current_time = time.time()\n",
    "    inference_time = datetime.timedelta(seconds=current_time - start_time)\n",
    "    print (\"\\tInferrence time: \", inference_time)\n",
    "    \n",
    "    # Draw boxes on frame\n",
    "    \n",
    "    \n",
    "    #import IPython;IPython.embed()\n",
    "    # THE FRAME WITH INFERRENCE BOXES\n",
    "    # make sure return is numpy array of same dimensions as input frame\n",
    "    resized_frame = imresize(frame, (720, 1280))\n",
    "    \n",
    "    return resized_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames:  111\n"
     ]
    }
   ],
   "source": [
    "video_input_filename = \"input-video-short.avi\"\n",
    "video_output_filename = \"OUTPUT_VIDEO.avi\"\n",
    "# Create video capture object to read video frames\n",
    "vid_read = cv2.VideoCapture(video_input_filename)\n",
    "TOTAL_FRAMES = int(vid_read.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Number of frames: \", TOTAL_FRAMES)\n",
    "# Create video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "vid_write = cv2.VideoWriter(video_output_filename, fourcc, 30.0, (1280, 720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of frame:  <class 'numpy.ndarray'>\n",
      "Frame size:  (720, 1280, 3) \tin width height channels\n",
      "Frame  0 / 111 = 0.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/root/anaconda3/lib/python3.6/site-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tInferrence time:  0:00:00.670058\n",
      "Frame  1 / 111 = 0.01\tInferrence time:  0:00:00.614524\n",
      "Frame  2 / 111 = 0.02\tInferrence time:  0:00:00.607133\n",
      "Frame  3 / 111 = 0.03\tInferrence time:  0:00:00.622149\n",
      "Frame  4 / 111 = 0.04\tInferrence time:  0:00:00.622580\n",
      "Frame  5 / 111 = 0.05\tInferrence time:  0:00:00.621972\n",
      "Frame  6 / 111 = 0.05\tInferrence time:  0:00:00.624533\n",
      "Frame  7 / 111 = 0.06\tInferrence time:  0:00:00.624927\n",
      "Frame  8 / 111 = 0.07\tInferrence time:  0:00:00.595549\n",
      "Frame  9 / 111 = 0.08\tInferrence time:  0:00:00.598557\n",
      "Frame  10 / 111 = 0.09\tInferrence time:  0:00:00.604035\n",
      "Frame  11 / 111 = 0.10\tInferrence time:  0:00:00.611480\n",
      "Frame  12 / 111 = 0.11\tInferrence time:  0:00:00.603230\n",
      "Frame  13 / 111 = 0.12\tInferrence time:  0:00:00.613628\n",
      "Frame  14 / 111 = 0.13\tInferrence time:  0:00:00.607586\n",
      "Frame  15 / 111 = 0.14\tInferrence time:  0:00:00.594297\n",
      "Frame  16 / 111 = 0.14\tInferrence time:  0:00:00.596434\n",
      "Frame  17 / 111 = 0.15\tInferrence time:  0:00:00.594436\n",
      "Frame  18 / 111 = 0.16\tInferrence time:  0:00:00.600993\n",
      "Frame  19 / 111 = 0.17\tInferrence time:  0:00:00.594781\n",
      "Frame  20 / 111 = 0.18\tInferrence time:  0:00:00.597477\n",
      "Frame  21 / 111 = 0.19\tInferrence time:  0:00:00.598212\n",
      "Frame  22 / 111 = 0.20\tInferrence time:  0:00:00.599536\n",
      "Frame  23 / 111 = 0.21\tInferrence time:  0:00:00.599430\n",
      "Frame  24 / 111 = 0.22\tInferrence time:  0:00:00.601760\n",
      "Frame  25 / 111 = 0.23\tInferrence time:  0:00:00.609942\n",
      "Frame  26 / 111 = 0.23\tInferrence time:  0:00:00.609362\n",
      "Frame  27 / 111 = 0.24\tInferrence time:  0:00:00.598488\n",
      "Frame  28 / 111 = 0.25\tInferrence time:  0:00:00.601222\n",
      "Frame  29 / 111 = 0.26\tInferrence time:  0:00:00.596966\n",
      "Frame  30 / 111 = 0.27\tInferrence time:  0:00:00.599526\n",
      "Frame  31 / 111 = 0.28\tInferrence time:  0:00:00.595117\n",
      "Frame  32 / 111 = 0.29\tInferrence time:  0:00:00.604489\n",
      "Frame  33 / 111 = 0.30\tInferrence time:  0:00:00.598473\n",
      "Frame  34 / 111 = 0.31\tInferrence time:  0:00:00.598823\n",
      "Frame  35 / 111 = 0.32\tInferrence time:  0:00:00.599442\n",
      "Frame  36 / 111 = 0.32\tInferrence time:  0:00:00.600105\n",
      "Frame  37 / 111 = 0.33\tInferrence time:  0:00:00.599730\n",
      "Frame  38 / 111 = 0.34\tInferrence time:  0:00:00.599115\n",
      "Frame  39 / 111 = 0.35\tInferrence time:  0:00:00.596421\n",
      "Frame  40 / 111 = 0.36\tInferrence time:  0:00:00.599011\n",
      "Frame  41 / 111 = 0.37\tInferrence time:  0:00:00.596172\n",
      "Frame  42 / 111 = 0.38\tInferrence time:  0:00:00.599516\n",
      "Frame  43 / 111 = 0.39\tInferrence time:  0:00:00.596848\n",
      "Frame  44 / 111 = 0.40\tInferrence time:  0:00:00.600497\n",
      "Frame  45 / 111 = 0.41\tInferrence time:  0:00:00.599794\n",
      "Frame  46 / 111 = 0.41\tInferrence time:  0:00:00.602351\n",
      "Frame  47 / 111 = 0.42\tInferrence time:  0:00:00.602447\n",
      "Frame  48 / 111 = 0.43\tInferrence time:  0:00:00.599578\n",
      "Frame  49 / 111 = 0.44\tInferrence time:  0:00:00.595646\n",
      "Frame  50 / 111 = 0.45\tInferrence time:  0:00:00.600302\n",
      "Frame  51 / 111 = 0.46\tInferrence time:  0:00:00.595172\n",
      "Frame  52 / 111 = 0.47\tInferrence time:  0:00:00.598758\n",
      "Frame  53 / 111 = 0.48\tInferrence time:  0:00:00.596185\n",
      "Frame  54 / 111 = 0.49\tInferrence time:  0:00:00.603029\n",
      "Frame  55 / 111 = 0.50\tInferrence time:  0:00:00.598991\n",
      "Frame  56 / 111 = 0.50\tInferrence time:  0:00:00.598086\n",
      "Frame  57 / 111 = 0.51\tInferrence time:  0:00:00.603641\n",
      "Frame  58 / 111 = 0.52\tInferrence time:  0:00:00.600392\n",
      "Frame  59 / 111 = 0.53\tInferrence time:  0:00:00.598301\n",
      "Frame  60 / 111 = 0.54\tInferrence time:  0:00:00.602755\n",
      "Frame  61 / 111 = 0.55\tInferrence time:  0:00:00.595827\n",
      "Frame  62 / 111 = 0.56\tInferrence time:  0:00:00.600803\n",
      "Frame  63 / 111 = 0.57\tInferrence time:  0:00:00.595542\n",
      "Frame  64 / 111 = 0.58\tInferrence time:  0:00:00.597303\n",
      "Frame  65 / 111 = 0.59\tInferrence time:  0:00:00.597060\n",
      "Frame  66 / 111 = 0.59\tInferrence time:  0:00:00.600234\n",
      "Frame  67 / 111 = 0.60\tInferrence time:  0:00:00.595194\n",
      "Frame  68 / 111 = 0.61\tInferrence time:  0:00:00.599172\n",
      "Frame  69 / 111 = 0.62\tInferrence time:  0:00:00.596790\n",
      "Frame  70 / 111 = 0.63\tInferrence time:  0:00:00.602781\n",
      "Frame  71 / 111 = 0.64\tInferrence time:  0:00:00.598355\n",
      "Frame  72 / 111 = 0.65\tInferrence time:  0:00:00.600913\n",
      "Frame  73 / 111 = 0.66\tInferrence time:  0:00:00.616766\n",
      "Frame  74 / 111 = 0.67\tInferrence time:  0:00:00.606299\n",
      "Frame  75 / 111 = 0.68\tInferrence time:  0:00:00.613096\n",
      "Frame  76 / 111 = 0.68\tInferrence time:  0:00:00.597140\n",
      "Frame  77 / 111 = 0.69\tInferrence time:  0:00:00.603082\n",
      "Frame  78 / 111 = 0.70\tInferrence time:  0:00:00.604169\n",
      "Frame  79 / 111 = 0.71\tInferrence time:  0:00:00.594764\n",
      "Frame  80 / 111 = 0.72\tInferrence time:  0:00:00.599597\n",
      "Frame  81 / 111 = 0.73\tInferrence time:  0:00:00.596168\n",
      "Frame  82 / 111 = 0.74\tInferrence time:  0:00:00.600297\n",
      "Frame  83 / 111 = 0.75\tInferrence time:  0:00:00.595030\n",
      "Frame  84 / 111 = 0.76\tInferrence time:  0:00:00.598855\n",
      "Frame  85 / 111 = 0.77\tInferrence time:  0:00:00.594386\n",
      "Frame  86 / 111 = 0.77\tInferrence time:  0:00:00.596120\n",
      "Frame  87 / 111 = 0.78\tInferrence time:  0:00:00.602428\n",
      "Frame  88 / 111 = 0.79\tInferrence time:  0:00:00.600483\n",
      "Frame  89 / 111 = 0.80\tInferrence time:  0:00:00.598990\n",
      "Frame  90 / 111 = 0.81\tInferrence time:  0:00:00.596754\n",
      "Frame  91 / 111 = 0.82\tInferrence time:  0:00:00.599894\n",
      "Frame  92 / 111 = 0.83\tInferrence time:  0:00:00.599233\n",
      "Frame  93 / 111 = 0.84\tInferrence time:  0:00:00.603254\n",
      "Frame  94 / 111 = 0.85\tInferrence time:  0:00:00.598346\n",
      "Frame  95 / 111 = 0.86\tInferrence time:  0:00:00.598471\n",
      "Frame  96 / 111 = 0.86\tInferrence time:  0:00:00.598216\n",
      "Frame  97 / 111 = 0.87\tInferrence time:  0:00:00.595549\n",
      "Frame  98 / 111 = 0.88\tInferrence time:  0:00:00.601378\n",
      "Frame  99 / 111 = 0.89\tInferrence time:  0:00:00.595984\n",
      "Frame  100 / 111 = 0.90\tInferrence time:  0:00:00.597373\n",
      "Frame  101 / 111 = 0.91\tInferrence time:  0:00:00.600071\n",
      "Frame  102 / 111 = 0.92\tInferrence time:  0:00:00.598743\n",
      "Frame  103 / 111 = 0.93\tInferrence time:  0:00:00.597420\n",
      "Frame  104 / 111 = 0.94\tInferrence time:  0:00:00.598662\n",
      "Frame  105 / 111 = 0.95\tInferrence time:  0:00:00.600187\n",
      "Frame  106 / 111 = 0.95\tInferrence time:  0:00:00.602512\n",
      "Frame  107 / 111 = 0.96\tInferrence time:  0:00:00.596481\n",
      "Frame  108 / 111 = 0.97\tInferrence time:  0:00:00.597728\n",
      "Frame  109 / 111 = 0.98\tInferrence time:  0:00:00.600206\n",
      "Frame  110 / 111 = 0.99\tInferrence time:  0:00:00.594876\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "success, frame = vid_read.read()\n",
    "print(\"Data type of frame: \", type(frame))\n",
    "print(\"Frame size: \", frame.shape, \"\\tin width height channels\")\n",
    "frame_num = 0\n",
    "while success:\n",
    "    print(\"Frame \", frame_num, \"/\", TOTAL_FRAMES, \"=\", \"%0.2f\" % (frame_num / TOTAL_FRAMES), end=\"\")\n",
    "    # Resize numpy array to correct size\n",
    "    resized_frame = imresize(frame, (img_size, img_size))\n",
    "    output_frame = infer_draw_frame(resized_frame)    \n",
    "    vid_write.write(output_frame)\n",
    "    # Read next frame from input\n",
    "    success, frame = vid_read.read()\n",
    "    frame_num += 1    \n",
    "    \n",
    "# Clean up    \n",
    "vid_read.release()\n",
    "vid_write.release()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
